{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa9bd9c1",
   "metadata": {},
   "source": [
    "# requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447118d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import albumentations as A \n",
    "from typing import Tuple\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage import io, transform\n",
    "from skimage.measure import label, regionprops\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4279cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"../\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3974065",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce470e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 255\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "def apply_masks_to_img(img, _id, df):\n",
    "    '''Apply masks to image given img, its id and the dataframe.'''\n",
    "    masks = df[df.ImageId == _id].EncodedPixels.apply(lambda x: rle_decode(x)).tolist()\n",
    "    masks = sum(masks)\n",
    "    return img * masks.reshape(img.shape[0], img.shape[1], 1)\n",
    "def get_img(imgid):\n",
    "    '''Return image array, given ID.'''\n",
    "    path = Path(f'{PROJECT_PATH}/data/train_v2/') / '{}'.format(imgid)\n",
    "    return plt.imread(path)\n",
    "#apply a particluar mask over the image \n",
    "def apply_mask(image, mask):\n",
    "    image = image.copy()\n",
    "    xs,ys = np.where(mask==255)\n",
    "    for x, y in zip(xs,ys):\n",
    "        image[x, y, [0,1]] = 255\n",
    "    return image\n",
    "def get_mask(image_id):\n",
    "    rle_code = self.dataframe_labels[self.dataframe_labels[\"ImageId\"]==image_id][\"EncodedPixels\"].values\n",
    "    rle_codes = df_train[df_train[\"image_path\"]==df_train.iloc[3][\"image_path\"]][\"EncodedPixels\"].values\n",
    "    mask = np.zeros((768,768),dtype=np.uint8)\n",
    "    for rle_code in rle_codes:\n",
    "        mask_ship = rle_to_mask(rle_code)\n",
    "        mask = cv2.bitwise_or(mask,mask_ship)\n",
    "def show_pixels_distribution(df):\n",
    "    \"\"\"\n",
    "    Prints the amount of ship and no-ship pixels in the df\n",
    "    \"\"\"\n",
    "    # Total images in the df\n",
    "    n_images = df['ImageId'].nunique() \n",
    "    \n",
    "    # Total pixels in the df\n",
    "    total_pixels = n_images * 768 * 768 \n",
    "\n",
    "    # Keep only rows with RLE boxes, transform them into list of pixels, sum the lengths of those lists\n",
    "    ship_pixels = df['EncodedPixels'].dropna().apply(rle_decode).str.len().sum() \n",
    "\n",
    "    ratio = ship_pixels / total_pixels\n",
    "    print(f\"Ship: {round(ratio, 3)} ({ship_pixels})\")\n",
    "    print(f\"No ship: {round(1 - ratio, 3)} ({total_pixels - ship_pixels})\")\n",
    "    \n",
    "def rle_codes_to_mask(rle_codes,image_size):\n",
    "    mask = np.zeros(image_size,dtype=np.uint8)\n",
    "    for rle_code in rle_codes:\n",
    "        mask_ship = rle_decode(rle_code)\n",
    "        mask = cv2.bitwise_or(mask,mask_ship)\n",
    "    return mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25d7b572",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{PROJECT_PATH}/data/train_ship_segmentations_v2.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e24547c7",
   "metadata": {},
   "source": [
    "# Initial statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab50aed",
   "metadata": {},
   "source": [
    "Let`s find the number of images in both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efca673",
   "metadata": {},
   "outputs": [],
   "source": [
    "ships = train[~train.EncodedPixels.isna()].ImageId.unique()\n",
    "noships = train[train.EncodedPixels.isna()].ImageId.unique()\n",
    "\n",
    "plt.bar(['Ships', 'No Ships'], [len(ships), len(noships)]);\n",
    "plt.ylabel('Number of Images');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bcb0c4a",
   "metadata": {},
   "source": [
    "We are observing highly imbalanced classes. Some weighted-robust metrics will be approriate to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train\n",
    "train_files = os.listdir(f\"{PROJECT_PATH}/data/train_v2/\")\n",
    "test_files = os.listdir(f\"{PROJECT_PATH}/data/test_v2/\")\n",
    "# Count number of ships per image\n",
    "df_wships = df_train.dropna()\n",
    "df_wships = df_wships.groupby('ImageId').size().reset_index(name='counts')\n",
    "df_woships = df_train[df_train['EncodedPixels'].isna()]\n",
    "\n",
    "print('Number of images with ships :     %d \\nNumber of images without ships : %d\\n  \\nProportion: %0.1f\\n ' \\\n",
    "      % (df_wships.shape[0], df_woships.shape[0], df_wships.shape[0] / df_woships.shape[0]))\n",
    "\n",
    "\n",
    "print('Ration with ships:     ' +str(round((df_wships.shape[0]/len(train_files)),2)))\n",
    "print('Ration without ships:  ' +str(round((df_woships.shape[0]/len(train_files)),2)))\n",
    "\n",
    "#make plots\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(['With ships','Without ships'], [len(df_wships),len(df_woships)], color = ['lightblue','pink'])\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Unbalanced Trainig Data')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(['With ships','Without ships'], [len(df_wships)/len(train_files),len(df_woships)/len(train_files)], \n",
    "        color = ['lightblue','pink'])\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Unbalanced Trainig Data (Normalized)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "hist = df_wships.hist(bins=np.arange(df_wships['counts'].max())+0.5)\n",
    "plt.xticks(range(15))\n",
    "plt.title(\"Histogram of ships count\")\n",
    "plt.xlabel(\"Number of ships\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show(hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92d2b638",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b26b1ab8",
   "metadata": {},
   "source": [
    "Let`s show a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ca7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = train[~train.EncodedPixels.isna()].sample(25)\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "for i, imgid in enumerate(sample.ImageId):\n",
    "    col = i % 5\n",
    "    row = i // 5\n",
    "    \n",
    "    path = Path(f'{PROJECT_PATH}/data/train_v2/') / '{}'.format(imgid)\n",
    "    img = plt.imread(path)\n",
    "    \n",
    "    ax[row, col].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some masks\n",
    "w = 6\n",
    "h = 2\n",
    "\n",
    "_, axes_list = plt.subplots(h, w, figsize=(2*w, 2*h))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "# ax.set(xlim=(0, 768), ylim=(0, 768))\n",
    "for axes in axes_list:\n",
    "    for ax in axes:\n",
    "        ax.axis('auto')\n",
    "        mask = rle_decode(np.random.choice(df_train.dropna()['EncodedPixels']))\n",
    "        ax.imshow(mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 6\n",
    "h = 2\n",
    "\n",
    "_, axes_list = plt.subplots(h, w, figsize=(2*w, 2*h))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "for axes in axes_list:\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        image_id = np.random.choice(df_train.dropna()['ImageId'])\n",
    "        rle_codes = df_train[df_train[\"ImageId\"]==image_id]['EncodedPixels'].values\n",
    "        mask = rle_codes_to_mask(rle_codes,(768,768))\n",
    "        image = plt.imread(f\"{PROJECT_PATH}/data/train_v2/{image_id}\")\n",
    "        image = apply_mask(image,mask)\n",
    "        ax.imshow(image);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d24c1b24",
   "metadata": {},
   "source": [
    "We can see that ships are mostly red or gray in color, while sea or ocean is black, green, or blue. Let`s find  color statistics "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d05dd57b",
   "metadata": {},
   "source": [
    "# Statistics by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = train.EncodedPixels.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 250\n",
    "sample_images_ids_without_ships = train[mask][\"ImageId\"].sample(sample_size,random_state=42).values\n",
    "sample_images_ids_with_ships = train[~mask].drop_duplicates().sample(sample_size,random_state=42)[\"ImageId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b52ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images_without_ships = np.array([get_img(_id) for _id in tqdm(sample_images_ids_without_ships)])\n",
    "sample_images_with_ships = np.array([get_img(_id) for _id in tqdm(sample_images_ids_with_ships)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af17686",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex='col')\n",
    "fig.set_size_inches(20, 6)\n",
    "\n",
    "for i,(imgs,label) in enumerate(zip([sample_images_with_ships,\n",
    "                                    sample_images_without_ships],\n",
    "                                    [\"With ships\",\"Without ships\"])):\n",
    "    red = imgs[:, :, :, 0]\n",
    "    green = imgs[:, :, :, 1]\n",
    "    blue = imgs[:, :, :, 2]\n",
    "\n",
    "    ax[i].plot(np.bincount(red.ravel()), color='orangered', label='red', lw=2)\n",
    "    ax[i].plot(np.bincount(green.ravel()), color='yellowgreen', label='green', lw=2)\n",
    "    ax[i].plot(np.bincount(blue.ravel()), color='skyblue', label='blue', lw=2)\n",
    "    ax[i].legend()\n",
    "    ax[i].title.set_text(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbde5eb8",
   "metadata": {},
   "source": [
    "As we can see from the plots above, the color distribution is more skewed for the images without ships. Also, the red color has local peaks with green and blue color on the left image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e545633",
   "metadata": {},
   "source": [
    "Results (considering the whole dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pixels_distribution(df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "786e3056",
   "metadata": {},
   "source": [
    "Results (considering only the images with ships):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pixels_distribution(df_train.dropna())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc3fc33d",
   "metadata": {},
   "source": [
    "<b>Conclusion:\n",
    "    \n",
    "The dataset is highly imbalanced, the training with Unet for the ship segmentation will require carefull selection of losses, including dice, also can be focal and other options. The augmentation can change existing images and help us to learn general distribution. The model needs to be trained for quite a long time for the results, so the concept weights will be presented. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
